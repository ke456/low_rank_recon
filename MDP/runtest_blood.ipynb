{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from runtest import *\n",
    "from Data_binary import *\n",
    "from statistics import median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training points: 493\n",
      "test points: 122\n"
     ]
    }
   ],
   "source": [
    "env = Data(unknown_rate=1)\n",
    "env.loadfile(\"hcv.csv\") # change this to the test file\n",
    "env.normalize()\n",
    "env.alpha = 0\n",
    "env.cluster_K_means(7)\n",
    "# this makes it so when we do the ranking, we only check against this number\n",
    "# of data points; ignore for now\n",
    "#env.set_validation(2000)\n",
    "# makes the costs uniform; we won't have groups either\n",
    "env.set_costs()\n",
    "\n",
    "# partition into training/test sets\n",
    "test_env = env.split(0.80)\n",
    "print(\"training points:\", len(env.data))\n",
    "print(\"test points:\", len(test_env.data))\n",
    "\n",
    "env.write_data(\"../tree/hcv_train.csv\")\n",
    "test_env.write_data(\"../tree/hcv_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs = [(i+1)/13 for i in range(13)] # list of maximum budgets\n",
    "results = [] # stores all the results for each value of budget\n",
    "for c in costs:\n",
    "    env.max_cost = c\n",
    "    test_env.max_cost = c\n",
    "    # take the average of 3 trainings\n",
    "    r1 = []\n",
    "    r2 = []\n",
    "    for i in range(3):\n",
    "        rtemp = runtest(env,test_env)\n",
    "        r1.append(rtemp[2])\n",
    "        r2.append(rtemp[3])\n",
    "    print(\"At cost:\", c, median(r1), median(r2))\n",
    "    results.append([r1,r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this value is the total distance between p and 5 closest predicted points to p\n",
    "resRL = [median(results[i][0]) for i in range(len(results))]\n",
    "resRAND = [median(results[i][1]) for i in range(len(results))]\n",
    "plt.plot(costs, resRL, 'r', costs, resRAND)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will write the results to BENCHMARK/<test>.csv\n",
    "f = open('BENCHMARK/hcv_test.csv', 'w')\n",
    "\n",
    "def write(f,lst):\n",
    "    for l in lst:\n",
    "        f.write(str(l))\n",
    "        f.write(' ')\n",
    "\n",
    "# first write the number of test points\n",
    "f.write(str(len(test_env.data)))\n",
    "f.write('\\n')\n",
    "        \n",
    "# write the cost\n",
    "write(f,costs)\n",
    "f.write('\\n')\n",
    "\n",
    "# write the RL result\n",
    "write(f,resRL)\n",
    "f.write('\\n')\n",
    "\n",
    "# finally write the random results\n",
    "write(f, resRAND)\n",
    "f.write('\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from runtest import *\n",
    "from Data_binary import *\n",
    "from statistics import median\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training points: 4657\n",
      "test points: 1163\n"
     ]
    }
   ],
   "source": [
    "env = Data(unknown_rate=1)\n",
    "env.loadfile(\"survey.csv\") # change this to the test file\n",
    "env.normalize()\n",
    "env.alpha = 0\n",
    "env.cluster_K_means(7)\n",
    "# this makes it so when we do the ranking, we only check against this number\n",
    "# of data points; ignore for now\n",
    "#env.set_validation(2000)\n",
    "# makes the costs uniform; we won't have groups either\n",
    "env.set_costs()\n",
    "\n",
    "# partition into training/test sets\n",
    "test_env = env.split(0.80)\n",
    "print(\"training points:\", len(env.data))\n",
    "print(\"test points:\", len(test_env.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 0.1\n",
      "random: 6541.354164365904 took 23.78960871696472 seconds\n",
      "random: 6542.181361178117 took 23.751585721969604 seconds\n",
      "random: 6489.180997453931 took 24.08489203453064 seconds\n",
      "median for RL: 6671.775504352538 median for random: 6541.354164365904\n",
      "mean for RL: 6671.775504352538 mean for random: 6524.238840999317\n",
      "\n",
      "cost 0.2\n",
      "random: 5563.270864834373 took 24.803722143173218 seconds\n",
      "random: 5538.81258862772 took 24.61825203895569 seconds\n",
      "random: 5533.461611012349 took 24.816554307937622 seconds\n",
      "median for RL: 4671.4068348421115 median for random: 5538.81258862772\n",
      "mean for RL: 4671.4068348421115 mean for random: 5545.181688158147\n",
      "\n",
      "cost 0.3\n",
      "random: 4965.429961504316 took 25.832474946975708 seconds\n"
     ]
    }
   ],
   "source": [
    "costs = [(i+1)/10 for i in range(10)] # list of maximum budgets\n",
    "gammas = {}\n",
    "for cost in costs:\n",
    "    gammas[cost]=0.8\n",
    "results = [] # stores all the results for each value of budget\n",
    "for c in costs:\n",
    "    env.max_cost = c\n",
    "    test_env.max_cost = c\n",
    "    # take the average of 3 trainings\n",
    "    r1 = []\n",
    "    r2 = []\n",
    "    \n",
    "    print(\"cost\",c)\n",
    "    \n",
    "    agent_distance = testAgent(env,test_env, \"survey\", c, gamma=gammas[c], max_eps=500, epsilon_decay=0.98)\n",
    "    r1.append(agent_distance)\n",
    "    \n",
    "    for i in range(3):\n",
    "        start = time.time()\n",
    "        random_distance = testRandom(env, test_env, c)\n",
    "        r2.append(random_distance)\n",
    "        print(\"random:\", random_distance, \"took\", time.time()-start,\"seconds\")\n",
    "    print(\"median for RL:\", median(r1), \"median for random:\",median(r2))\n",
    "    print(\"mean for RL:\", np.mean(r1), \"mean for random:\",np.mean(r2))\n",
    "    print()\n",
    "    results.append([r1,r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this value is the total distance between p and 5 closest predicted points to p\n",
    "resRL = [results[i][0] for i in range(len(results))]\n",
    "resRAND = [median(results[i][1]) for i in range(len(results))]\n",
    "plt.plot(costs, resRL, 'r', costs, resRAND)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will write the results to BENCHMARK/<test>.csv\n",
    "f = open('BENCHMARK/survey_test.csv', 'w')\n",
    "\n",
    "def write(f,lst):\n",
    "    for l in lst:\n",
    "        f.write(str(l))\n",
    "        f.write(' ')\n",
    "\n",
    "# first write the number of test points\n",
    "f.write(str(len(test_env.data)))\n",
    "f.write('\\n')\n",
    "        \n",
    "# write the cost\n",
    "write(f,costs)\n",
    "f.write('\\n')\n",
    "\n",
    "# write the RL result\n",
    "write(f,resRL)\n",
    "f.write('\\n')\n",
    "\n",
    "# finally write the random results\n",
    "write(f, resRAND)\n",
    "f.write('\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
